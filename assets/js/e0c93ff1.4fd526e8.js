"use strict";(self.webpackChunkApache_Cloudberry_Incubating_website=self.webpackChunkApache_Cloudberry_Incubating_website||[]).push([[2066],{16835:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>p,frontMatter:()=>i,metadata:()=>o,toc:()=>l});var t=s(85893),r=s(11151);const i={title:"[102] Apache Cloudberry Crash Course",description:"If you want to learn the Apache Cloudberry quickly, follow this crash course."},a=void 0,o={type:"mdx",permalink:"/bootcamp/102-cbdb-crash-course",source:"@site/src/pages/bootcamp/102-cbdb-crash-course.md",title:"[102] Apache Cloudberry Crash Course",description:"If you want to learn the Apache Cloudberry quickly, follow this crash course.",frontMatter:{title:"[102] Apache Cloudberry Crash Course",description:"If you want to learn the Apache Cloudberry quickly, follow this crash course."},unlisted:!1},d={},l=[{value:"Lesson 0. Prerequisite",id:"lesson-0-prerequisite",level:2},{value:"Lesson 1. Where to read the official documentation",id:"lesson-1-where-to-read-the-official-documentation",level:2},{value:"Lesson 2. How to install CBDB",id:"lesson-2-how-to-install-cbdb",level:2},{value:"Lesson 3. Cluster architecture",id:"lesson-3-cluster-architecture",level:2},{value:"Lesson 4. Management utilities",id:"lesson-4-management-utilities",level:2},{value:"Lesson 5. Start and stop a cluster",id:"lesson-5-start-and-stop-a-cluster",level:2},{value:"Lesson 6. Check cluster state",id:"lesson-6-check-cluster-state",level:2},{value:"Lesson 7. How CBDB segment mirroring works",id:"lesson-7-how-cbdb-segment-mirroring-works",level:2},{value:"Lesson 8. CBDB&#39;s fault tolerance and segment recovery",id:"lesson-8-cbdbs-fault-tolerance-and-segment-recovery",level:2},{value:"Lesson 9. Set up and manage the standby master instance in CBDB",id:"lesson-9-set-up-and-manage-the-standby-master-instance-in-cbdb",level:2},{value:"Lesson 10. Expand a cluster",id:"lesson-10-expand-a-cluster",level:2},{value:"Lesson 11. Check cluster performance",id:"lesson-11-check-cluster-performance",level:2},{value:"Lesson 12. User data and table distribution",id:"lesson-12-user-data-and-table-distribution",level:2},{value:"Lesson 13. Database catalog",id:"lesson-13-database-catalog",level:2},{value:"Lesson 14. CBDB data directories",id:"lesson-14-cbdb-data-directories",level:2},{value:"Lesson 15. Instance processes",id:"lesson-15-instance-processes",level:2},{value:"master processes:",id:"master-processes",level:4},{value:"primary processes:",id:"primary-processes",level:4},{value:"mirror processes:",id:"mirror-processes",level:4},{value:"Lesson 16. Database log files",id:"lesson-16-database-log-files",level:2},{value:"Lesson 17. Table types in CBDB: heap, AO, and AOCO",id:"lesson-17-table-types-in-cbdb-heap-ao-and-aoco",level:2},{value:"Lesson 18. External tables",id:"lesson-18-external-tables",level:2},{value:"Lesson 19. Workload management",id:"lesson-19-workload-management",level:2}];function c(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.a)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"This crash course provides an extensive overview of Apache Cloudberry, an open-source Massively Parallel Processing (MPP) database. It covers key concepts, features, utilities, and hands-on exercises to become proficient with CBDB."}),"\n",(0,t.jsx)(n.p,{children:"Topics include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-0-prerequisite",children:"Lesson 0. Prerequisite"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-1-where-to-read-the-official-documentation",children:"Lesson 1. Where to read the official documentation"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-2-how-to-install-cbdb",children:"Lesson 2. How to install CBDB"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-3-cluster-architecture",children:"Lesson 3. Cluster architecture"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-4-management-utilities",children:"Lesson 4. Management utilities"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-5-start-and-stop-a-cluster",children:"Lesson 5. Start and stop a cluster"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-6-check-cluster-state",children:"Lesson 6. Check cluster state"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-7-how-cbdb-segment-mirroring-works",children:"Lesson 7. How CBDB segment mirroring works"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-8-cbdbs-fault-tolerance-and-segment-recovery",children:"Lesson 8. CBDB's fault tolerance and segment recovery"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-9-set-up-and-manage-the-standby-master-instance-in-cbdb",children:"Lesson 9. Set up and manage the standby master instance in CBDB"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-10-expand-a-cluster",children:"Lesson 10. Expand a cluster"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-11-check-cluster-performance",children:"Lesson 11. Check cluster performance"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-12-user-data-and-table-distribution",children:"Lesson 12. User data and table distribution"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-13-database-catalog",children:"Lesson 13. Database catalog"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-14-cbdb-data-directories",children:"Lesson 14. CBDB data directories"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#lesson-15-instance-processes",children:"Lesson 15. Instance processes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#master-processes",children:"master processes:"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#primary-processes",children:"primary processes:"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#mirror-processes",children:"mirror processes:"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-16-database-log-files",children:"Lesson 16. Database log files"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-17-table-types-in-cbdb-heap-ao-and-aoco",children:"Lesson 17. Table types in CBDB: heap, AO, and AOCO"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-18-external-tables",children:"Lesson 18. External tables"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#lesson-19-workload-management",children:"Lesson 19. Workload management"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-0-prerequisite",children:"Lesson 0. Prerequisite"}),"\n",(0,t.jsxs)(n.p,{children:["Before starting this crash course, spend some time going through the ",(0,t.jsx)(n.a,{href:"./#1-cloudberry-sandbox",children:"Apache Cloudberry Tutorials Based on Single-Node Installation"})," to get familiar with Apache Cloudberry and how it works."]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-1-where-to-read-the-official-documentation",children:"Lesson 1. Where to read the official documentation"}),"\n",(0,t.jsxs)(n.p,{children:["Take a quick look at the official ",(0,t.jsx)(n.a,{href:"https://cloudberry.apache.org/docs",children:"Cloudberry Documentation"}),". No need to worry if you do not understand everything."]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-2-how-to-install-cbdb",children:"Lesson 2. How to install CBDB"}),"\n",(0,t.jsx)(n.p,{children:"To begin your journey with CBDB, you are expected to install CBDB in your preferred environment. The following options are available:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["For testing or trying out CBDB in a sandbox environment, see ",(0,t.jsx)(n.a,{href:"./cbdb-sandbox",children:"Install Cloudberry in a Sandbox"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["For deploying CBDB in other environments (including the production environment) and the prerequisite software/hardware configuration, see ",(0,t.jsx)(n.a,{href:"https://cloudberry.apache.org/docs/cbdb-op-deploy-guide",children:"Cloudberry Deployment Guide"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-3-cluster-architecture",children:"Lesson 3. Cluster architecture"}),"\n",(0,t.jsxs)(n.p,{children:["A CBDB cluster has one master host (usually named ",(0,t.jsx)(n.code,{children:"mdw"}),") and multiple segment hosts (usually named ",(0,t.jsx)(n.code,{children:"sdwXX"}),")."]}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.p,{children:["If someone is referring to ",(0,t.jsx)(n.code,{children:"mdw"}),', he is referring to the "master host". Similarly, when somebody is referring to "sdw10", he is referring to the 10th segment host.']})}),"\n",(0,t.jsxs)(n.p,{children:["A master host usually contains only one instance - the master instance. The segment hosts might contain many worker instances. Every instance has its own set of processes, data directory, and listening port. For example, usually, the listening port of the master instance (where all clients will connect to) is ",(0,t.jsx)(n.code,{children:"5432"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Every segment instance has its own listening port, and the base port is specified in the cluster configuration file."}),"\n",(0,t.jsx)(n.p,{children:"Instances can have 2 roles - primary and mirror. Primary instances serve database queries. Mirror instances simply track and record data changes in primary instances, but do not serve database queries. If the primary instance goes down for some reason, then the corresponding mirror instance transitions to the primary role and starts serving queries (the original primary instance, currently down, is marked as mirror)."}),"\n",(0,t.jsxs)(n.p,{children:["The cluster information is stored in the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"}),' system table, which looks like this (use the "psql" command to connect to the database to execute queries):']}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:'[gpadmin@mdw ~]$ psql\n\npsql (14.4, server 14.4)\nType "help" for help.\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"gpadmin=# SELECT * FROM gp_segment_configuration;\n\n dbid | content | role | preferred_role | mode | status | port  | hostname | address |            datadir\n------+---------+------+----------------+------+--------+-------+----------+---------+--------------------------------\n    1 |      -1 | p    | p              | n    | u      |  5432 | mdw      | mdw     | /data0/database/master/gpseg-1\n    2 |       0 | p    | p              | n    | u      | 40000 | mdw      | mdw     | /data0/database/primary/gpseg0\n    3 |       1 | p    | p              | n    | u      | 40001 | mdw      | mdw     | /data0/database/primary/gpseg1\n(3 rows)\n"})}),"\n",(0,t.jsx)(n.p,{children:"The columns of this system are described as follows."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"dbid"}),": uniquely identifies a segment."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"content"}),": uniquely identifies segment pairs (primary and mirror). The primary and the corresponding mirror will have the same ",(0,t.jsx)(n.code,{children:"content"})," ID, but different ",(0,t.jsx)(n.code,{children:"dbid"})," values. The master has the ",(0,t.jsx)(n.code,{children:"content"})," value of ",(0,t.jsx)(n.code,{children:"-1"}),". The worker instances have incremental content values of ",(0,t.jsx)(n.code,{children:"0"}),", ",(0,t.jsx)(n.code,{children:"1"}),", ",(0,t.jsx)(n.code,{children:"2"}),", ",(0,t.jsx)(n.code,{children:"3"}),"..."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"role"}),": the current role of the segment."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"preferred_role"}),": the role of the segment in the original configuration. Note that if an original mirror instance has taken over and become primary now, the role will be changed. This column records the original role."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"mode"}),": the mode of the segment. The value options are ",(0,t.jsx)(n.code,{children:"s"})," (in sync), ",(0,t.jsx)(n.code,{children:"c"})," (in change tracking), and ",(0,t.jsx)(n.code,{children:"r"})," (in recovery)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"status"}),": the status of the segment. The value options are ",(0,t.jsx)(n.code,{children:"u"})," (up) and ",(0,t.jsx)(n.code,{children:"d"})," (down)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"port"}),": the listening port of the segment. For clients, only the listening port of the master is important. The segment listening ports are important for the master to communicate with them."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"hostname"}),": the hostname of the segment."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"address"}),": each host can have different network controllers with different IP addresses and different names associated."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"datadir"}),": the data directory where data is stored for each segment."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsxs)(n.p,{children:["Connect to the CBDB cluster that you have created and take a look at the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table. Try to learn the rows and columns. Take a look at the cluster configuration file that you used to create the cluster."]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-4-management-utilities",children:"Lesson 4. Management utilities"}),"\n",(0,t.jsx)(n.p,{children:"Management utilities in CBDB are command-line tools used to administer and manage the database cluster. Some key points:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"They allow performing tasks like starting, stopping, and configuring the database."}),"\n",(0,t.jsx)(n.li,{children:"Help monitor the health and status of the cluster."}),"\n",(0,t.jsx)(n.li,{children:"Used for maintenance like recovering nodes and rebalancing data."}),"\n",(0,t.jsx)(n.li,{children:"Help scale out the cluster by expanding with more nodes."}),"\n",(0,t.jsx)(n.li,{children:"Utilities work across master, standby master, and multiple segment instances."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"In summary, management utilities are command-line programs and scripts used by DBAs to administer, monitor, maintain and manage a CBDB cluster. The following are some common utilities."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"gpstop"}),": stops database cluster."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"gpstart"}),": starts database cluster."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"psql"}),": a command-line client."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"gpconfig"}),": shows or changes configuration parameters."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"gpdeletesystem"}),": deletes a cluster."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"pg_dump"}),", ",(0,t.jsx)(n.code,{children:"gpbackup"}),", ",(0,t.jsx)(n.code,{children:"gprestore"}),": performs backup and restore operations."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"gpinitstanby"}),", ",(0,t.jsx)(n.code,{children:"gpactivatestandby"}),": manages the standby master instance."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"gprecoverseg"}),": recovers segment."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"gpfdist"}),", ",(0,t.jsx)(n.code,{children:"gpload"}),": operates with external tables."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"gpssh"}),", ",(0,t.jsx)(n.code,{children:"gpscp"}),", ",(0,t.jsx)(n.code,{children:"gpssh-exkeys"}),": for cluster navigation."]}),"\n",(0,t.jsxs)(n.li,{children:["Logging - all utilities write log files under ",(0,t.jsx)(n.code,{children:"~/gpAdminLogs/"})," - one file per day"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsxs)(n.p,{children:["Read the help information for these tools (",(0,t.jsx)(n.code,{children:"<tool_name> --help"}),")."]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-5-start-and-stop-a-cluster",children:"Lesson 5. Start and stop a cluster"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Start a CBDB cluster using ",(0,t.jsx)(n.code,{children:"gpstart"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"[gpadmin@mdw ~]$ gpstart -a\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Starting gpstart with args: -a\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Gathering information and validating the environment...\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Cloudberry Binary Version: 'postgres (Apache Cloudberry) 1.0.0 build dev'\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Cloudberry Catalog Version: '302206171'\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Starting Coordinator instance in admin mode\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-CoordinatorStart pg_ctl cmd is env GPSESSID=0000000000 GPERA=None $GPHOME/bin/pg_ctl -D /data0/database/master/gpseg-1 -l /data0/database/master/gpseg-1/log/startup.log -w -t 600 -o \" -p 5432 -c gp_role=utility \" start\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Obtaining Cloudberry Coordinator catalog information\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Obtaining Segment details from coordinator...\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Setting new coordinator era\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Coordinator Started...\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Shutting down coordinator\n20230823:16:14:23:004256 gpstart:mdw:gpadmin-[INFO]:-Commencing parallel primary and mirror segment instance startup, please wait...\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-Process results...\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-   Successful segment starts                                            = 4\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-   Failed segment starts                                                = 0\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-   Skipped segment starts (segments are marked down in configuration)   = 0\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-Successfully started 4 of 4 segment instances\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-Starting Coordinator instance mdw directory /data0/database/master/gpseg-1\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-CoordinatorStart pg_ctl cmd is env GPSESSID=0000000000 GPERA=45b5ca734de32094_230823161423 $GPHOME/bin/pg_ctl -D /data0/database/master/gpseg-1 -l /data0/database/master/gpseg-1/log/startup.log -w -t 600 -o \" -p 5432 -c gp_role=dispatch \" start\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-Command pg_ctl reports Coordinator mdw instance active\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-Connecting to db template1 on host localhost\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-No standby coordinator configured.  skipping...\n20230823:16:14:24:004256 gpstart:mdw:gpadmin-[INFO]:-Database successfully started\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Stop a CBDB cluster using ",(0,t.jsx)(n.code,{children:"gpstop"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"[gpadmin@mdw ~]$ gpstop -a\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"20230823:16:14:18:004143 gpstop:mdw:gpadmin-[INFO]:-Starting gpstop with args: -a\n20230823:16:14:18:004143 gpstop:mdw:gpadmin-[INFO]:-Gathering information and validating the environment...\n20230823:16:14:18:004143 gpstop:mdw:gpadmin-[INFO]:-Obtaining Cloudberry Coordinator catalog information\n20230823:16:14:18:004143 gpstop:mdw:gpadmin-[INFO]:-Obtaining Segment details from coordinator...\n20230823:16:14:18:004143 gpstop:mdw:gpadmin-[INFO]:-Cloudberry Version: 'postgres (Apache Cloudberry) 1.0.0 build dev'\n20230823:16:14:18:004143 gpstop:mdw:gpadmin-[INFO]:-Commencing Coordinator instance shutdown with mode='smart'\n20230823:16:14:18:004143 gpstop:mdw:gpadmin-[INFO]:-Coordinator segment instance directory=/data0/database/master/gpseg-1\n20230823:16:14:18:004143 gpstop:mdw:gpadmin-[INFO]:-Stopping coordinator segment and waiting for user connections to finish ...\nserver shutting down\n20230823:16:14:19:004143 gpstop:mdw:gpadmin-[INFO]:-Attempting forceful termination of any leftover coordinator process\n20230823:16:14:19:004143 gpstop:mdw:gpadmin-[INFO]:-Terminating processes for segment /data0/database/master/gpseg-1\n20230823:16:14:19:004143 gpstop:mdw:gpadmin-[INFO]:-No standby coordinator host configured\n20230823:16:14:19:004143 gpstop:mdw:gpadmin-[INFO]:-Targeting dbid [2, 4, 3, 5] for shutdown\n20230823:16:14:19:004143 gpstop:mdw:gpadmin-[INFO]:-Commencing parallel primary segment instance shutdown, please wait...\n20230823:16:14:19:004143 gpstop:mdw:gpadmin-[INFO]:-0.00% of jobs completed\n20230823:16:14:19:004143 gpstop:mdw:gpadmin-[INFO]:-100.00% of jobs completed\n20230823:16:14:19:004143 gpstop:mdw:gpadmin-[INFO]:-Commencing parallel mirror segment instance shutdown, please wait...\n20230823:16:14:19:004143 gpstop:mdw:gpadmin-[INFO]:-0.00% of jobs completed\n20230823:16:14:20:004143 gpstop:mdw:gpadmin-[INFO]:-100.00% of jobs completed\n20230823:16:14:20:004143 gpstop:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:14:20:004143 gpstop:mdw:gpadmin-[INFO]:-   Segments stopped successfully      = 4\n20230823:16:14:20:004143 gpstop:mdw:gpadmin-[INFO]:-   Segments with errors during stop   = 0\n20230823:16:14:20:004143 gpstop:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:14:20:004143 gpstop:mdw:gpadmin-[INFO]:-Successfully shutdown 4 of 4 segment instances\n20230823:16:14:20:004143 gpstop:mdw:gpadmin-[INFO]:-Database successfully shutdown with no errors reported\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsxs)(n.p,{children:["Read the log entries for ",(0,t.jsx)(n.code,{children:"gpstop"})," and ",(0,t.jsx)(n.code,{children:"gpstart"}),", and try to understand what they mean. Read and exercise the different options for ",(0,t.jsx)(n.code,{children:"gpstart"})," and ",(0,t.jsx)(n.code,{children:"gpstop"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-6-check-cluster-state",children:"Lesson 6. Check cluster state"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Check the state of a cluster using ",(0,t.jsx)(n.code,{children:"gpstate"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"gpstate"})," is the utility that can give you information about the state of the cluster. You can add different options to see different aspects of the cluster state."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"[gpadmin@mdw ~]$ gpstate\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-Starting gpstate with args:\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-local Cloudberry Version: 'postgres (Apache Cloudberry) 1.0.0 build dev'\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-coordinator Cloudberry Version: 'PostgreSQL 14.4 (Apache Cloudberry 1.0.0 build dev) on aarch64-unknown-linux-gnu, compiled by gcc (GCC) 10.2.1 20210130 (Red Hat 10.2.1-11), 64-bit compiled on Aug  9 2023 14:45:43'\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-Obtaining Segment details from coordinator...\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-Gathering data from segments...\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-Cloudberry instance status summary\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Coordinator instance                                      = Active\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Coordinator standby                                       = No coordinator standby configured\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total segment instance count from metadata                = 4\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Primary Segment Status\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total primary segments                                    = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total primary segment valid (at coordinator)              = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total primary segment failures (at coordinator)           = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of postmaster.pid files missing              = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of postmaster.pid files found                = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of postmaster.pid PIDs missing               = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of postmaster.pid PIDs found                 = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of /tmp lock files missing                   = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of /tmp lock files found                     = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number postmaster processes missing                 = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number postmaster processes found                   = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Mirror Segment Status\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-----------------------------------------------------\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total mirror segments                                     = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total mirror segment valid (at coordinator)               = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total mirror segment failures (at coordinator)            = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of postmaster.pid files missing              = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of postmaster.pid files found                = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of postmaster.pid PIDs missing               = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of postmaster.pid PIDs found                 = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of /tmp lock files missing                   = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number of /tmp lock files found                     = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number postmaster processes missing                 = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number postmaster processes found                   = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number mirror segments acting as primary segments   = 0\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-   Total number mirror segments acting as mirror segments    = 2\n20230823:16:17:41:004530 gpstate:mdw:gpadmin-[INFO]:-----------------------------------------------------\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Check the status of a cluster by querying the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," system table. The ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"}),' table displays the "master instance" information about the state of the cluster.']}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsxs)(n.p,{children:["Check the cluster state and try to collect the information using ",(0,t.jsx)(n.code,{children:"gpstate"})," or ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-7-how-cbdb-segment-mirroring-works",children:"Lesson 7. How CBDB segment mirroring works"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"CBDB mirroring overview:"})}),"\n",(0,t.jsx)(n.p,{children:"Each segment instance in a Apache Cloudberry has 2 possible roles: primary and mirror."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Primary role: serves user queries."}),"\n",(0,t.jsx)(n.li,{children:"Mirror role: tracks and records data changes from the primary using WAL replication but does not serve user queries."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"If the primary segment instance encounters an issue and goes down, its corresponding mirror segment takes over the primary role to ensure continuity in serving queries. The system will then mark the original, now non-functional, primary segment as a mirror."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Segment modes"})}),"\n",(0,t.jsx)(n.p,{children:"A segment can exist in one of the following modes:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"s"}),": In sync."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"c"}),": Change tracking."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"r"}),": In recovery."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["The ideal state for both primary and mirror segments is to be up and in-sync (represented as ",(0,t.jsx)(n.code,{children:"P:u/s"})," and ",(0,t.jsx)(n.code,{children:"M:u/s"}),")."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Scenarios for CBDB mirroring"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Scenario 1: When the mirror instance goes down, the following process occurs."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["The primary segment transitions from the in-sync mode to the change tracking mode (",(0,t.jsx)(n.code,{children:"P:u/c"})," and ",(0,t.jsx)(n.code,{children:"M:d/s"}),")."]}),"\n",(0,t.jsx)(n.li,{children:"All data changes are recorded and stored."}),"\n",(0,t.jsxs)(n.li,{children:["The DBA, upon noticing this, investigates and starts a recovery for the mirror instance using the ",(0,t.jsx)(n.code,{children:"gprecoverseg"})," command."]}),"\n",(0,t.jsxs)(n.li,{children:["Both the primary and mirror segments transition to the recovery mode (",(0,t.jsx)(n.code,{children:"P:u/r"}),", ",(0,t.jsx)(n.code,{children:"M:u/r"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:["Post recovery, both the primary and mirror segments revert to the in-sync mode (",(0,t.jsx)(n.code,{children:"P:u/s"}),", ",(0,t.jsx)(n.code,{children:"M:u/s"}),")."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This scenario remains transparent to users because the primary segment is still functional. Therefore, queries continue to run without interruptions."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Scenario 2: When the primary instance goes down, the following process occurs."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"All active sessions on the primary instance are terminated."}),"\n",(0,t.jsxs)(n.li,{children:['The database system marks the primary instance as "down" and promotes the mirror instance to the primary role, enabling it to track changes (',(0,t.jsx)(n.code,{children:"M:d/s"}),", ",(0,t.jsx)(n.code,{children:"P:u/c"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:["The DBA, upon detecting this situation, investigates and starts recovering the mirror using the ",(0,t.jsx)(n.code,{children:"gprecoverseg"})," command."]}),"\n",(0,t.jsxs)(n.li,{children:["On starting the recovery, both primary and mirror segments transition to the recovery mode ",(0,t.jsx)(n.code,{children:"(M:u/r"}),", ",(0,t.jsx)(n.code,{children:"P:u/r"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:["Once the recovery is completed, both segments switch to the in-sync mode (",(0,t.jsx)(n.code,{children:"M:u/s"}),", ",(0,t.jsx)(n.code,{children:"P:u/s"}),")."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"After this recovery, the roles of the instances have been changed (the original primary is now a mirror). To revert the segments to their original roles, you need to rebalance them. This can be done by either:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Using the ",(0,t.jsx)(n.code,{children:"gpstop"})," and ",(0,t.jsx)(n.code,{children:"gpstart"})," commands."]}),"\n",(0,t.jsxs)(n.li,{children:["Using the ",(0,t.jsx)(n.code,{children:"gprecoverseg -r"})," command for rebalancing."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Add mirrors to an existing cluster"})}),"\n",(0,t.jsxs)(n.p,{children:["If your CBDB cluster was initially created without mirrors, you can use the ",(0,t.jsx)(n.code,{children:"gpaddmirrors"})," utility to add mirrors to the existing cluster. See the following example:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"[gpadmin@mdw ~]$ gpaddmirrors\n"})}),"\n",(0,t.jsxs)(s,{children:[(0,t.jsx)("summary",{children:"The example output of gpaddmirrors"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"20230823:16:02:50:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Starting gpaddmirrors with args:\n20230823:16:02:50:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-local Cloudberry Version: 'postgres (Apache Cloudberry) 1.0.0 build dev'\n20230823:16:02:50:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-coordinator Cloudberry Version: 'PostgreSQL 14.4 (Apache Cloudberry 1.0.0 build dev) on aarch64-unknown-linux-gnu, compiled by gcc (GCC) 10.2.1 20210130 (Red Hat 10.2.1-11), 64-bit compiled on Aug  9 2023 14:45:43'\n20230823:16:02:50:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Obtaining Segment details from coordinator...\n20230823:16:02:50:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Successfully finished pg_controldata /data0/database/primary/gpseg0 for dbid 2:\nstdout: pg_control version number:            13000700\nCatalog version number:               302206171\nDatabase system identifier:           7270424369249924934\nDatabase cluster state:               in production\npg_control last modified:             Wed 23 Aug 2023 03:59:52 PM CST\nLatest checkpoint location:           0/50EBA18\nLatest checkpoint's REDO location:    0/50EB9E0\nLatest checkpoint's REDO WAL file:    000000010000000000000001\nLatest checkpoint's TimeLineID:       1\nLatest checkpoint's PrevTimeLineID:   1\nLatest checkpoint's full_page_writes: on\nLatest checkpoint's NextXID:          0:762\nLatest checkpoint's NextGxid:         1\nLatest checkpoint's NextOID:          13266\nLatest checkpoint's NextRelfilenode:  12002\nLatest checkpoint's NextMultiXactId:  1\nLatest checkpoint's NextMultiOffset:  0\nLatest checkpoint's oldestXID:        752\nLatest checkpoint's oldestXID's DB:   1\nLatest checkpoint's oldestActiveXID:  761\nLatest checkpoint's oldestMultiXid:   1\nLatest checkpoint's oldestMulti's DB: 1\nLatest checkpoint's oldestCommitTsXid:0\nLatest checkpoint's newestCommitTsXid:0\nTime of latest checkpoint:            Wed 23 Aug 2023 03:59:52 PM CST\nFake LSN counter for unlogged rels:   0/3E8\nMinimum recovery ending location:     0/0\nMin recovery ending loc's timeline:   0\nBackup start location:                0/0\nBackup end location:                  0/0\nEnd-of-backup record required:        no\nwal_level setting:                    replica\nwal_log_hints setting:                off\nmax_connections setting:              60\nmax_worker_processes setting:         13\nmax_wal_senders setting:              10\nmax_prepared_xacts setting:           250\nmax_locks_per_xact setting:           128\ntrack_commit_timestamp setting:       off\nMaximum data alignment:               8\nDatabase block size:                  32768\nBlocks per segment of large relation: 32768\nWAL block size:                       32768\nBytes per WAL segment:                67108864\nMaximum length of identifiers:        64\nMaximum columns in an index:          32\nMaximum size of a TOAST chunk:        8140\nSize of a large-object chunk:         8192\nDate/time type storage:               64-bit integers\nFloat8 argument passing:              by value\nData page checksum version:           1\nMock authentication nonce:            94edd2a762753f7d12faff1737ffb338dec6e01a90eb3d509c6afc67e78bf58e\nFile encryption method:\n\nstderr:\n20230823:16:02:50:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Successfully finished pg_controldata /data0/database/primary/gpseg1 for dbid 3:\nstdout: pg_control version number:            13000700\nCatalog version number:               302206171\nDatabase system identifier:           7270424369087874885\nDatabase cluster state:               in production\npg_control last modified:             Wed 23 Aug 2023 03:59:52 PM CST\nLatest checkpoint location:           0/50EBA18\nLatest checkpoint's REDO location:    0/50EB9E0\nLatest checkpoint's REDO WAL file:    000000010000000000000001\nLatest checkpoint's TimeLineID:       1\nLatest checkpoint's PrevTimeLineID:   1\nLatest checkpoint's full_page_writes: on\nLatest checkpoint's NextXID:          0:762\nLatest checkpoint's NextGxid:         1\nLatest checkpoint's NextOID:          13266\nLatest checkpoint's NextRelfilenode:  12002\nLatest checkpoint's NextMultiXactId:  1\nLatest checkpoint's NextMultiOffset:  0\nLatest checkpoint's oldestXID:        752\nLatest checkpoint's oldestXID's DB:   1\nLatest checkpoint's oldestActiveXID:  761\nLatest checkpoint's oldestMultiXid:   1\nLatest checkpoint's oldestMulti's DB: 1\nLatest checkpoint's oldestCommitTsXid:0\nLatest checkpoint's newestCommitTsXid:0\nTime of latest checkpoint:            Wed 23 Aug 2023 03:59:52 PM CST\nFake LSN counter for unlogged rels:   0/3E8\nMinimum recovery ending location:     0/0\nMin recovery ending loc's timeline:   0\nBackup start location:                0/0\nBackup end location:                  0/0\nEnd-of-backup record required:        no\nwal_level setting:                    replica\nwal_log_hints setting:                off\nmax_connections setting:              60\nmax_worker_processes setting:         13\nmax_wal_senders setting:              10\nmax_prepared_xacts setting:           250\nmax_locks_per_xact setting:           128\ntrack_commit_timestamp setting:       off\nMaximum data alignment:               8\nDatabase block size:                  32768\nBlocks per segment of large relation: 32768\nWAL block size:                       32768\nBytes per WAL segment:                67108864\nMaximum length of identifiers:        64\nMaximum columns in an index:          32\nMaximum size of a TOAST chunk:        8140\nSize of a large-object chunk:         8192\nDate/time type storage:               64-bit integers\nFloat8 argument passing:              by value\nData page checksum version:           1\nMock authentication nonce:            baf9fb0b44c5cc558357b266024336445d958e35f8896fcd94b5ef2143ad052d\nFile encryption method:\n\nstderr:\n20230823:16:02:50:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Heap checksum setting consistent across cluster\nEnter mirror segment data directory location 1 of 2 >\n/data0/database/mirror\nEnter mirror segment data directory location 2 of 2 >\n/data0/database/mirror\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Cloudberry Add Mirrors Parameters\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:---------------------------------------------\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Cloudberry coordinator data directory    = /data0/database/master/gpseg-1\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Cloudberry coordinator port              = 5432\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Batch size                              = 16\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Segment batch size                      = 64\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:---------------------------------------------\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Mirror 1 of 2\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:---------------------------------------------\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Primary instance host        = mdw\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Primary instance address     = mdw\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Primary instance directory   = /data0/database/primary/gpseg0\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Primary instance port        = 40000\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Mirror instance host         = mdw\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Mirror instance address      = mdw\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Mirror instance directory    = /data0/database/mirror/gpseg0\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Mirror instance port         = 41000\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:---------------------------------------------\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Mirror 2 of 2\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:---------------------------------------------\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Primary instance host        = mdw\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Primary instance address     = mdw\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Primary instance directory   = /data0/database/primary/gpseg1\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Primary instance port        = 40001\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Mirror instance host         = mdw\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Mirror instance address      = mdw\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Mirror instance directory    = /data0/database/mirror/gpseg1\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-   Mirror instance port         = 41001\n20230823:16:03:16:003517 gpaddmirrors:mdw:gpadmin-[INFO]:---------------------------------------------\n\nContinue with add mirrors procedure Yy|Nn (default=N):\n> y\n20230823:16:03:30:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Starting to create new pg_hba.conf on primary segments\n20230823:16:03:31:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Successfully modified pg_hba.conf on primary segments to allow replication connections\n20230823:16:03:31:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-2 segment(s) to add\n20230823:16:03:31:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Setting up the required segments for recovery\n20230823:16:03:31:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Running recovery for the required segments\nmdw (dbid 4): pg_basebackup: base backup completed\nmdw (dbid 5): pg_basebackup: base backup completed\n20230823:16:03:33:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Updating configuration with new mirrors\n20230823:16:03:33:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Starting mirrors\n20230823:16:03:33:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-era is 45b5ca734de32094_230823155950\n20230823:16:03:33:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Commencing parallel segment instance startup, please wait...\n20230823:16:03:34:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Process results...\n20230823:16:03:34:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-\n20230823:16:03:34:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-******************************************************************\n20230823:16:03:34:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Mirror segments have been added; data synchronization is in progress.\n20230823:16:03:34:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Data synchronization will continue in the background.\n20230823:16:03:34:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-Use  gpstate -s  to check the resynchronization progress.\n20230823:16:03:34:003517 gpaddmirrors:mdw:gpadmin-[INFO]:-******************************************************************\n"})}),(0,t.jsx)("br",{})]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsx)(n.p,{children:"Add mirrors to your cluster. If your cluster already has mirrors, delete the cluster and recreate one without mirrors (removing mirror segments is not supported)."}),"\n",(0,t.jsx)(n.h2,{id:"lesson-8-cbdbs-fault-tolerance-and-segment-recovery",children:"Lesson 8. CBDB's fault tolerance and segment recovery"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"CBDB's fault tolerance system"})}),"\n",(0,t.jsx)(n.p,{children:'CBDB\'s Fault Tolerant Service (FTS) continuously watches over the cluster to ensure uninterrupted work with active segments. If a segment goes down, the system makes adjustments to ensure a primary instance is always ready for every content. A situation where both the primary and mirror instances of a content fail is called a "double fault," rendering the database unusable.'}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Working principle of the FTS service"})}),"\n",(0,t.jsxs)(n.p,{children:['The FTS service operates from the master node using the "ftsprober" process. This process periodically scans segments. If it identifies any changes compared to the last saved configuration, it makes the necessary adjustments. Details about these adjustments are stored in the master log file and the ',(0,t.jsx)(n.code,{children:"gp_configuration_history"})," table, while the status of each instance is updated in the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table."]}),"\n",(0,t.jsxs)(n.p,{children:["The following is a preview of the ",(0,t.jsx)(n.code,{children:"gp_configuration_history"})," table:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sql",children:"gpadmin=# SELECT * FROM gp_configuration_history;\n\n             time              | dbid |                                      desc\n-------------------------------+------+--------------------------------------------------------------------------------\n 2023-08-23 16:03:33.917057+08 |    4 | gpaddmirrors: segment config for resync: inserted mirror segment configuration\n 2023-08-23 16:03:33.917057+08 |    5 | gpaddmirrors: segment config for resync: inserted mirror segment configuration\n 2023-08-23 16:03:52.784083+08 |    2 | FTS: update role, status, and mode for dbid 2 with contentid 0 to p, u, and s\n 2023-08-23 16:03:52.78515+08  |    4 | FTS: update role, status, and mode for dbid 4 with contentid 0 to m, u, and s\n 2023-08-23 16:03:52.794198+08 |    3 | FTS: update role, status, and mode for dbid 3 with contentid 1 to p, u, and s\n 2023-08-23 16:03:52.794214+08 |    5 | FTS: update role, status, and mode for dbid 5 with contentid 1 to m, u, and s\n(6 rows)\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Recover a downed segment"})}),"\n",(0,t.jsxs)(n.p,{children:["If a segment is down, you can recover it using the ",(0,t.jsx)(n.code,{children:"gprecoverseg"})," utility. This tool will read the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table, identify the downed segment, and try to recover it using its related primary segment. However, for this recovery to work, the primary segment must be active."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Investigate segment failures"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Check the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table to find the downed segments and their mirrors."]}),"\n",(0,t.jsx)(n.li,{children:'Read the master log file to determine when the failure occurred. Look for log entries that start with "FTS:".'}),"\n",(0,t.jsxs)(n.li,{children:["Read the ",(0,t.jsx)(n.code,{children:"gp_configuration_history"})," table to see a list of logged events."]}),"\n",(0,t.jsx)(n.li,{children:"Check the primary and mirror log files to understand why the segment failed."}),"\n",(0,t.jsxs)(n.li,{children:["Once you know the cause of the failure, use ",(0,t.jsx)(n.code,{children:"gprecoverseg"})," to restore the segments."]}),"\n",(0,t.jsxs)(n.li,{children:["To keep an eye on the recovery, use the ",(0,t.jsx)(n.code,{children:"gpstate -e"})," command."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Find the processes related to one of your database instances and stop it."}),"\n",(0,t.jsxs)(n.li,{children:["Watch the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table for any changes."]}),"\n",(0,t.jsxs)(n.li,{children:["Next, read the master log file and again check the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table."]}),"\n",(0,t.jsx)(n.li,{children:"To fix the failed segment, use the recovery tools."}),"\n",(0,t.jsxs)(n.li,{children:["Confirm in the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table that the segment has been recovered."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-9-set-up-and-manage-the-standby-master-instance-in-cbdb",children:"Lesson 9. Set up and manage the standby master instance in CBDB"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Understand the role of the standby master"})}),"\n",(0,t.jsx)(n.p,{children:'In the CBDB architecture, the master instance can be a single point of failure. To avoid this, it is recommended to set up and maintain a "standby master" instance. Typically, this standby instance is set up on a distinct server, referred to as the "standby master server" or "smdw".'}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Manage standby master"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["To create the standby master (from the master server), use ",(0,t.jsx)(n.code,{children:"gpinitstandby -s smdw"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["If the standby master falls out-of-sync, you can resynchronize it using ",(0,t.jsx)(n.code,{children:"gpinitstandby -n"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["To remove the standby master, use ",(0,t.jsx)(n.code,{children:"gpinitstandby -r"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["After setting up the standby instance, you can query the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table. In the table output, the new standby instance will be visible, which is identified by a ",(0,t.jsx)(n.code,{children:"content"})," value of ",(0,t.jsx)(n.code,{children:"-1"})," and a ",(0,t.jsx)(n.code,{children:"role"})," value of ",(0,t.jsx)(n.code,{children:"'m'"}),"."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Promote the standby master"})}),"\n",(0,t.jsxs)(n.p,{children:["If the master server or master instance is unavailable, the standby master can step in to take its place. To promote the standby master to the role of the master, run the ",(0,t.jsx)(n.code,{children:"gpactivatestandby"})," command from the standby server."]}),"\n",(0,t.jsxs)(n.p,{children:["Upon running this command, the roles change: the standby master becomes the master, while the original master gets demoted to the role of the standby instance, although it remains offline. You can query the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table again to notice these changes."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Create the standby master."}),"\n",(0,t.jsx)(n.li,{children:"Remove the standby master."}),"\n",(0,t.jsx)(n.li,{children:"Create the standby master again."}),"\n",(0,t.jsx)(n.li,{children:"Activate this standby master to make it the primary master."}),"\n",(0,t.jsx)(n.li,{children:"Create another standby master on the original master server."}),"\n",(0,t.jsx)(n.li,{children:"Activate this new standby master."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Throughout these steps, keep an eye on the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table. This will help you understand the changes in roles and the state of each instance."]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-10-expand-a-cluster",children:"Lesson 10. Expand a cluster"}),"\n",(0,t.jsxs)(n.p,{children:["If you need to expand a cluster, you can use the ",(0,t.jsx)(n.code,{children:"gpexpand"})," tool. You can add new hosts or more segments to the current hosts."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Steps to expand a cluster"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Run ",(0,t.jsx)(n.code,{children:"gpexpand"})," and answer questions."]}),"\n",(0,t.jsx)(n.p,{children:'Run "gpexpand". In this step, you will be guided to answer questions about what you want to do. After answering all the questions, it makes a "configuration file" and stops. You should look at this file to check whether it is doing what you want.'}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Run ",(0,t.jsx)(n.code,{children:"gpexpand -i <config_file>"})," to create new instances for the cluster."]}),"\n",(0,t.jsxs)(n.p,{children:["This step creates the new instances of the cluster. These new instances will show up in the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table. The cluster is now expanded, but the new instances do not have the data from users yet."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"gpexpand"})," also makes a new area called the ",(0,t.jsx)(n.code,{children:"gpexpand"})," schema. This area has a list of tables that need to be spread out in the next step."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Run ",(0,t.jsx)(n.code,{children:"gpexpand"})," again to redistribute or spread out the data."]}),"\n",(0,t.jsxs)(n.p,{children:["Here, the data, which was only in the old instances, is now spread out to the expanded cluster. You can do this step many times by setting a time limit with the ",(0,t.jsx)(n.code,{children:"-d"})," option. When all data is spread out, ",(0,t.jsx)(n.code,{children:"gpexpand"})," stops."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Finish up."}),"\n",(0,t.jsxs)(n.p,{children:["Now, the cluster is expanded and the data is spread out. The ",(0,t.jsx)(n.code,{children:"gpexpand"})," schema is still there. You can look at it if you need to. It will not cause any problems."]}),"\n",(0,t.jsxs)(n.p,{children:["But if you want to expand the cluster again, ",(0,t.jsx)(n.code,{children:"gpexpand"})," will tell you to remove it using ",(0,t.jsx)(n.code,{children:"gpexpand -c"})," before it can continue."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Run ",(0,t.jsx)(n.code,{children:"gpexpand"})," to add more segments to your current servers."]}),"\n",(0,t.jsxs)(n.li,{children:["Run ",(0,t.jsx)(n.code,{children:"gpexpand"})," again to add segments on new servers."]}),"\n",(0,t.jsxs)(n.li,{children:["Look at the ",(0,t.jsx)(n.code,{children:"gp_segment_configuration"})," table to see how it changes with each action."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-11-check-cluster-performance",children:"Lesson 11. Check cluster performance"}),"\n",(0,t.jsxs)(n.p,{children:["You can use the ",(0,t.jsx)(n.code,{children:"gpcheckperf"})," utility to check performance on a set of hosts (cluster). This utility can be used to check the following:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["I/O performance per host (with the ",(0,t.jsx)(n.code,{children:"-r -d"})," options)"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["Note: gpcheckperf will use the ",(0,t.jsx)(n.code,{children:"dd"})," command to perform read test and write test on each host."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Network performance (with the ",(0,t.jsx)(n.code,{children:"-r -n|N|M"})," options)"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["Note: ",(0,t.jsx)(n.code,{children:"-n"})," means sequential. ",(0,t.jsx)(n.code,{children:"-N"})," means parallel with even number of hosts. ",(0,t.jsx)(n.code,{children:"-M"})," means full matrix mode."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Memory bandwidth test per host (with the ",(0,t.jsx)(n.code,{children:"-r -s"})," options)"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"Note: The utility uses the STREAM benchmark program to measure sustainable memory bandwidth (in MB/s)."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsxs)(n.p,{children:["Run ",(0,t.jsx)(n.code,{children:"gpcheckcat"})," with the various options and interpret the results."]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-12-user-data-and-table-distribution",children:"Lesson 12. User data and table distribution"}),"\n",(0,t.jsx)(n.p,{children:"In CBDB, the master instance does not store user data. Segments store user data, and the data is not shared between segments."}),"\n",(0,t.jsx)(n.p,{children:"All CBDB Database tables are distributed. When you create or alter a table, you optionally specify DISTRIBUTED BY (hash distribution), DISTRIBUTED RANDOMLY (random distribution), or DISTRIBUTED REPLICATED (fully distributed) to determine the table row distribution."}),"\n",(0,t.jsx)(n.p,{children:"Consider the following points when deciding on a table distribution policy."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:"Even Data Distribution"})," \u2014 For the best possible performance, all segments should contain equal portions of data. If the data is unbalanced or skewed, the segments with more data must work harder to perform their portion of the query processing. Choose a distribution key that is unique for each record, such as the primary key."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:"Local and Distributed Operations"})," \u2014 Local operations are faster than distributed operations. Query processing is fastest if the work associated with join, sort, or aggregation operations is done locally, at the segment level. Work done at the system level requires distributing tuples across the segments, which is less efficient. When tables share a common distribution key, the work of joining or sorting on their shared distribution key columns is done locally. With a random distribution policy, local join operations are not an option."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:"Even Query Processing"})," \u2014 For best performance, all segments should handle an equal share of the query workload. Query workload can be skewed if a table's data distribution policy and the query predicates are not well matched. For example, suppose that a sales transactions table is distributed on the customer ID column (the distribution key). If a predicate in a query references a single customer ID, the query processing work is concentrated on just one segment."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The replicated table distribution policy (DISTRIBUTED REPLICATED) should be used only for small tables. Replicating data to every segment is costly in both storage and maintenance, and prohibitive for large fact tables. The primary use cases for replicated tables are to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"remove restrictions on operations that user-defined functions can perform on segments, and"}),"\n",(0,t.jsx)(n.li,{children:"improve query performance by making it unnecessary to broadcast frequently used tables to all segments."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:'In the following example, we can see the vaule "1" for c1 column is alwasy located in the same segment (gp_segment_id=1) if the table is distributed by hash.'}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"gpadmin=# create table t1 (c1 int) distributed by (c1);\nCREATE TABLE\n\ngpadmin=# insert into t1 values (1);\nINSERT 0 1\ngpadmin=# insert into t1 values (1);\nINSERT 0 1\ngpadmin=# insert into t1 values (1);\nINSERT 0 1\ngpadmin=# insert into t1 values (1);\nINSERT 0 1\n\ngpadmin=# select gp_segment_id, * from t1;\n gp_segment_id | c1\n---------------+----\n             1 |  1\n             1 |  1\n             1 |  1\n             1 |  1\n(4 rows)\n\n"})}),"\n",(0,t.jsx)(n.p,{children:'In the following example, we can see the vaule "1" for c1 column is randomly distributed on all segments (gp_segment_id=0 and gp_segment_id=1) if the table is distributed randomly.'}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"gpadmin=# create table t2 (c1 int) distributed randomly;\nCREATE TABLE\n\ngpadmin=# insert into t2 values (1);\nINSERT 0 1\ngpadmin=# insert into t2 values (1);\nINSERT 0 1\ngpadmin=# insert into t2 values (1);\nINSERT 0 1\ngpadmin=# insert into t2 values (1);\nINSERT 0 1\n\ngpadmin=# select gp_segment_id, * from t2;\n gp_segment_id | c1\n---------------+----\n             0 |  1\n             1 |  1\n             1 |  1\n             1 |  1\n(4 rows)\n"})}),"\n",(0,t.jsx)(n.p,{children:"Exercise: Reproduce the above with your own table and observe the effects."}),"\n",(0,t.jsx)(n.h2,{id:"lesson-13-database-catalog",children:"Lesson 13. Database catalog"}),"\n",(0,t.jsxs)(n.p,{children:["System tables prefixed with ",(0,t.jsx)(n.em,{children:"gp_"})," relate to the parallel features of CBDB Database. Tables prefixed with ",(0,t.jsx)(n.em,{children:"pg_"})," are either standard PostgreSQL system catalog tables supported in CBDB Database, or are related to features CBDB that provides to enhance PostgreSQL for data warehousing workloads. Note that the global system catalog for CBDB Database resides on the coordinator instance."]}),"\n",(0,t.jsx)(n.p,{children:"Exercise: Run the following query to get a list of catalog table names."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"select tablename from pg_tables where schemaname='pg_catalog';\n"})}),"\n",(0,t.jsx)(n.h2,{id:"lesson-14-cbdb-data-directories",children:"Lesson 14. CBDB data directories"}),"\n",(0,t.jsxs)(n.p,{children:["In the master instance, the data directory is located at ",(0,t.jsx)(n.code,{children:"/data0/database/master/gpseg-1"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"The following are the contents in the data directory of the master instance and coordinator instance:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"[gpadmin@mdw gpseg-1]$ ls -tlr\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"total 156\n-rw------- 1 gpadmin gpadmin     3 Aug 23 15:59 PG_VERSION\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_twophase\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_tblspc\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_snapshots\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_serial\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_replslot\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_notify\ndrwx------ 4 gpadmin gpadmin  4096 Aug 23 15:59 pg_multixact\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_dynshmem\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_cryptokeys\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_commit_ts\n-rw------- 1 gpadmin gpadmin    88 Aug 23 15:59 postgresql.auto.conf\n-rw------- 1 gpadmin gpadmin  1636 Aug 23 15:59 pg_ident.conf\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_xact\ndrwx------ 3 gpadmin gpadmin  4096 Aug 23 15:59 pg_wal\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_subtrans\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_distributedlog\n-rw------- 1 gpadmin gpadmin 31760 Aug 23 15:59 postgresql.conf\n-rw------- 1 gpadmin gpadmin    10 Aug 23 15:59 internal.auto.conf\n-rw-rw-r-- 1 gpadmin gpadmin   860 Aug 23 15:59 gpssh.conf\ndrwx------ 6 gpadmin gpadmin  4096 Aug 23 15:59 base\n-rw-rw-r-- 1 gpadmin gpadmin  4723 Aug 23 15:59 pg_hba.conf\n-rw------- 1 gpadmin gpadmin    38 Aug 23 16:14 current_logfiles\n-rw------- 1 gpadmin gpadmin   112 Aug 23 16:14 postmaster.opts\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 16:14 pg_stat\n-rw------- 1 gpadmin gpadmin   130 Aug 23 16:14 gpsegconfig_dump\n-rw------- 1 gpadmin gpadmin    88 Aug 23 16:14 postmaster.pid\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 16:14 log\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 16:14 global\ndrwx------ 4 gpadmin gpadmin  4096 Aug 23 16:39 pg_logical\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 16:44 pg_stat_tmp\n"})}),"\n",(0,t.jsxs)(n.p,{children:["In the segment instances, the data directory is located at ",(0,t.jsx)(n.code,{children:"/data0/database/primary/gpseg0"})," and ",(0,t.jsx)(n.code,{children:"/data0/database/primary/gpseg1"}),". The following are the contents in the data directory of a segment instance:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"[gpadmin@mdw gpseg-1]$ cd /data0/database/primary/gpseg0\n[gpadmin@mdw gpseg0]$ ls -ltr\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"total 180\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_twophase\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_tblspc\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_snapshots\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_serial\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_notify\ndrwx------ 4 gpadmin gpadmin  4096 Aug 23 15:59 pg_multixact\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_dynshmem\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_cryptokeys\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_commit_ts\n-rw------- 1 gpadmin gpadmin     3 Aug 23 15:59 PG_VERSION\n-rw------- 1 gpadmin gpadmin  1636 Aug 23 15:59 pg_ident.conf\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_xact\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_subtrans\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 15:59 pg_distributedlog\n-rw------- 1 gpadmin gpadmin 31637 Aug 23 15:59 postgresql.conf\n-rw------- 1 gpadmin gpadmin    10 Aug 23 15:59 internal.auto.conf\n-rw------- 1 gpadmin gpadmin  4915 Aug 23 16:03 pg_hba.conf\ndrwx------ 7 gpadmin gpadmin  4096 Aug 23 16:03 base\ndrwx------ 3 gpadmin gpadmin  4096 Aug 23 16:03 pg_replslot\ndrwx------ 3 gpadmin gpadmin  4096 Aug 23 16:03 pg_wal\n-rw------- 1 gpadmin gpadmin   120 Aug 23 16:03 postgresql.auto.conf\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 16:14 log\n-rw------- 1 gpadmin gpadmin    38 Aug 23 16:14 current_logfiles\n-rw------- 1 gpadmin gpadmin   112 Aug 23 16:14 postmaster.opts\n-rw------- 1 gpadmin gpadmin    89 Aug 23 16:14 postmaster.pid\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 16:14 pg_stat\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 16:29 global\ndrwx------ 4 gpadmin gpadmin  4096 Aug 23 16:44 pg_logical\n-rw------- 1 gpadmin gpadmin 32768 Aug 23 16:44 fts_probe_file.bak\ndrwx------ 2 gpadmin gpadmin  4096 Aug 23 16:44 pg_stat_tmp\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsx)(n.p,{children:"Explore the data directory and subdirectories. Take a look at the configuration files."}),"\n",(0,t.jsx)(n.h2,{id:"lesson-15-instance-processes",children:"Lesson 15. Instance processes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"postgres process: the process with the data directory in its name (-D ...) - this process is the parent for all other database processes and it handles connections to this instance"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"logger process: writes log entries in the log file"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"stats collector process: statistics collector is a subsystem that supports collection and reporting of information about server activity. Presently, the collector can count accesses to tables and indexes in both disk-block and individual-row terms."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:'background writer process: writes "dirty" (new or modified) buffers to the on-disk datafiles.'}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"sweeper process: related to workload management and prioritization"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"checkpoint process: performs checkpoints"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"walwriter process: periodically flushes the WAL buffer to disk"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"ftsprobe process: runs in the coordinator node, and periodically polls the segments to maintain the status of each segment."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"walsender process: runs in primary segment, and sends the WALs to the mirror segment"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"walreceiver process:  runs in mirror segment, and receives WALs from primary segment"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"conXXX: user connection worker process"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"master-processes",children:"master processes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[gpadmin@mdw ~]$ ps aux|grep 5432\ngpadmin   4409  0.0  0.4 209960 39776 ?        Ss   16:14   0:00 /usr/local/cloudberry-db/bin/postgres -D /data0/database/master/gpseg-1 -p 5432 -c gp_role=dispatch\ngpadmin   4410  0.0  0.0  45544  5160 ?        Ss   16:14   0:00 postgres:  5432, master logger process\ngpadmin   4412  0.0  0.1 210256  9484 ?        Ss   16:14   0:00 postgres:  5432, checkpointer\ngpadmin   4413  0.0  0.0 210124  7440 ?        Ss   16:14   0:00 postgres:  5432, background writer\ngpadmin   4414  0.0  0.1 210124 10304 ?        Ss   16:14   0:00 postgres:  5432, walwriter\ngpadmin   4415  0.0  0.1 211544 12068 ?        Ss   16:14   0:00 postgres:  5432, autovacuum launcher\ngpadmin   4416  0.0  0.0  45768  5672 ?        Ss   16:14   0:00 postgres:  5432, stats collector\ngpadmin   4417  0.0  0.2 278596 22164 ?        Ssl  16:14   0:00 postgres:  5432, dtx recovery process\ngpadmin   4418  0.0  0.2 278416 21624 ?        Ssl  16:14   0:00 postgres:  5432, ftsprobe process\ngpadmin   4427  0.0  0.1 211492 11244 ?        Ss   16:14   0:00 postgres:  5432, logical replication launcher\ngpadmin   4428  0.0  0.2 277792 17748 ?        Ssl  16:14   0:00 postgres:  5432, pg_cron launcher\ngpadmin   4429  0.0  0.0 210124  5316 ?        Ss   16:14   0:00 postgres:  5432, sweeper process\ngpadmin   4846  0.0  0.5 294692 48516 ?        Ssl  16:25   0:00 postgres:  5432, gpadmin gpadmin [local] con46 cmd172 idle\n"})}),"\n",(0,t.jsx)(n.h4,{id:"primary-processes",children:"primary processes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[gpadmin@mdw ~]$ ps aux|grep 40000\ngpadmin   4373  0.0  0.5 212912 41404 ?        Ss   16:14   0:00 /usr/local/cloudberry-db/bin/postgres -D /data0/database/primary/gpseg0 -p 40000 -c gp_role=execute\ngpadmin   4377  0.0  0.0  45540  5272 ?        Ss   16:14   0:00 postgres: 40000, logger process\ngpadmin   4390  0.0  0.1 213212  9328 ?        Ss   16:14   0:00 postgres: 40000, checkpointer\ngpadmin   4391  0.0  0.0 213076  7856 ?        Ss   16:14   0:00 postgres: 40000, background writer\ngpadmin   4392  0.0  0.1 213076 10428 ?        Ss   16:14   0:00 postgres: 40000, walwriter\ngpadmin   4393  0.0  0.1 213784  9948 ?        Ss   16:14   0:00 postgres: 40000, autovacuum launcher\ngpadmin   4394  0.0  0.0  45768  5816 ?        Ss   16:14   0:00 postgres: 40000, stats collector\ngpadmin   4395  0.0  0.0 213624  7984 ?        Ss   16:14   0:00 postgres: 40000, logical replication launcher\ngpadmin   4396  0.0  0.0 212912  4480 ?        Ss   16:14   0:00 postgres: 40000, sweeper process\ngpadmin   4400  0.0  0.1 214868 12432 ?        Ss   16:14   0:00 postgres: 40000, walsender gpadmin 172.17.0.2(37278) streaming 0/100F9088\n"})}),"\n",(0,t.jsx)(n.h4,{id:"mirror-processes",children:"mirror processes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[gpadmin@mdw ~]$ ps aux|grep 41000\ngpadmin   4375  0.0  0.5 212912 41196 ?        Ss   16:14   0:00 /usr/local/cloudberry-db/bin/postgres -D /data0/database/mirror/gpseg0 -p 41000 -c gp_role=execute\ngpadmin   4379  0.0  0.0  45540  5160 ?        Ss   16:14   0:00 postgres: 41000, logger process\ngpadmin   4383  0.0  0.1 213344 10908 ?        Ss   16:14   0:00 postgres: 41000, startup recovering 000000010000000000000004\ngpadmin   4385  0.0  0.1 212912  8352 ?        Ss   16:14   0:00 postgres: 41000, checkpointer\ngpadmin   4386  0.0  0.0 212912  6260 ?        Ss   16:14   0:00 postgres: 41000, background writer\ngpadmin   4387  0.1  0.1 213788  9740 ?        Ss   16:14   0:04 postgres: 41000, walreceiver streaming 0/100F9088\n"})}),"\n",(0,t.jsx)(n.p,{children:"Exercise: Try to identify the processes for the instances in your cluster."}),"\n",(0,t.jsx)(n.h2,{id:"lesson-16-database-log-files",children:"Lesson 16. Database log files"}),"\n",(0,t.jsxs)(n.p,{children:["Each instance has its own log files which are located in the ",(0,t.jsx)(n.code,{children:"<data_directory>/log"})," directory."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"[gpadmin@mdw log]$ pwd\n\n/data0/database/primary/gpseg0/log\n\n[gpadmin@mdw log]$ ls -ltr\n\ntotal 20\n-rw------- 1 gpadmin gpadmin 8842 Aug 23 16:14 gpdb-2023-08-23_155951.csv\n-rw------- 1 gpadmin gpadmin  468 Aug 23 16:14 startup.log\n-rw------- 1 gpadmin gpadmin 3269 Aug 23 16:17 gpdb-2023-08-23_161424.csv\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The standard log file name is ",(0,t.jsx)(n.code,{children:"gpdb_<date>-<time>.csv"}),"."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsx)(n.p,{children:"Look at the log file and do different things in the database (create table, run queries, etc.)"}),"\n",(0,t.jsx)(n.h2,{id:"lesson-17-table-types-in-cbdb-heap-ao-and-aoco",children:"Lesson 17. Table types in CBDB: heap, AO, and AOCO"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Heap tables"})}),"\n",(0,t.jsxs)(n.p,{children:['In CBDB, the standard table type is "heap". These tables store rows on pages, and one data file can contain multiple pages. They support common SQL tasks such as ',(0,t.jsx)(n.code,{children:"SELECT"}),", ",(0,t.jsx)(n.code,{children:"INSERT"}),", ",(0,t.jsx)(n.code,{children:"UPDATE"}),", ",(0,t.jsx)(n.code,{children:"DELETE"}),", and ",(0,t.jsx)(n.code,{children:"TRUNCATE"}),". Each row in a heap table has a header. However, these tables do not support compression."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"AO tables"})}),"\n",(0,t.jsx)(n.p,{children:"Unlike heap tables, AO tables do not have a row header but they do allow compression. This feature makes AO tables a good fit for big fact tables."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"AOCO (column-oriented) tables"})}),"\n",(0,t.jsxs)(n.p,{children:["For tasks that focus on single columns, like average (",(0,t.jsx)(n.code,{children:"AVG"}),") or sum, using row-oriented storage is not the ideal option. Instead, column-oriented tables, which store data by its column, are more efficient. This is because when you query one column, it does not get slowed down by the size or count of other columns."]}),"\n",(0,t.jsx)(n.p,{children:"AOCO tables offer compression, and they compress even better than AO tables. This is due to the consistent type of data in one file, which means that all data in a single column is of the same kind."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsxs)(n.p,{children:["Make a heap table, an AO table, and an AOCO table. After creating them, use the ",(0,t.jsx)(n.code,{children:"\\d+ psql"})," command to view the results."]}),"\n",(0,t.jsx)(n.h2,{id:"lesson-18-external-tables",children:"Lesson 18. External tables"}),"\n",(0,t.jsx)(n.p,{children:"CBDB supports external tables. These tables are set up in the database, but they link to data outside of the database. Here is where the data for these tables can come from:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"A file on your local filesystem."}),"\n",(0,t.jsxs)(n.li,{children:["A file on a remote host (you need to use the ",(0,t.jsx)(n.code,{children:"gpfdist"})," server for this)."]}),"\n",(0,t.jsxs)(n.li,{children:["HDFS, which stands for the ",(0,t.jsx)(n.code,{children:"gphdfs"})," type."]}),"\n",(0,t.jsx)(n.li,{children:"Data generated on the spot with a command."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["One good thing about external tables is that they make it easy to load data into CBDB. When you use a command like ",(0,t.jsx)(n.code,{children:"INSERT INTO table SELECT * FROM ext_table"}),", data gets loaded all at once from different parts, instead of one piece at a time."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsx)(n.p,{children:"Try making different types of external tables and play around with them to learn more."}),"\n",(0,t.jsx)(n.h2,{id:"lesson-19-workload-management",children:"Lesson 19. Workload management"}),"\n",(0,t.jsx)(n.p,{children:"In CBDB, we have something called Resource Queues, or RQ for short. Think of an RQ as a group of sessions that need similar things and share resources. You can put any user into an RQ."}),"\n",(0,t.jsxs)(n.p,{children:["Also, there is a feature called Priority. You can set a priority level for a whole RQ, which means every session in that RQ will have that priority. But if you want, you can set a priority for just one session using the ",(0,t.jsx)(n.code,{children:"gp_adjust_priority()"})," function."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Exercise"})}),"\n",(0,t.jsx)(n.p,{children:"Make a user, set up an RQ, put the user in the RQ, then run a query. Watch and see what happens to the RQ."})]})}function p(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},11151:(e,n,s)=>{s.d(n,{Z:()=>o,a:()=>a});var t=s(67294);const r={},i=t.createContext(r);function a(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);